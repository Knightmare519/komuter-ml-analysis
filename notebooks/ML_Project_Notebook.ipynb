{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253733a7",
   "metadata": {},
   "source": [
    "# WIA1006/WID3006 Machine Learning Group Project\n",
    "\n",
    "## Team Members\n",
    "- Member 1\n",
    "- Member 2\n",
    "- Member 3\n",
    "- Member 4\n",
    "\n",
    "## Project Theme\n",
    "**Selected Theme:** [Choose between: Crop Production by District OR Hourly Origin-Destination Ridership: Komuter]\n",
    "\n",
    "**Dataset Source:** [Include link to dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff1318",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "\n",
    "### Project Objective\n",
    "[Define the specific machine learning problem you're trying to solve based on your chosen theme]\n",
    "\n",
    "### Research Questions\n",
    "1. [First research question related to your theme]\n",
    "2. [Second research question related to your theme]\n",
    "3. [Third research question related to your theme]\n",
    "\n",
    "### Expected Outcomes\n",
    "[Describe what insights or predictions you hope to achieve with your machine learning models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc2292",
   "metadata": {},
   "source": [
    "## 2. Data Collection/Acquisition\n",
    "\n",
    "In this section, we'll import the necessary libraries and load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a341a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# For visualization settings\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b763e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'your_dataset_url' with the actual URL or file path\n",
    "# Example for the crop production theme:\n",
    "# url = 'https://data.gov.my/data-catalogue/crops_district_production'\n",
    "# df = pd.read_csv(url)\n",
    "\n",
    "# If using a local file:\n",
    "# df = pd.read_csv('crop_production_data.csv')\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f233d5",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Preprocessing\n",
    "\n",
    "### 3.1 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdaa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "# df.info()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e91959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f35490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of key features\n",
    "# For example, if using the crop production dataset:\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.histplot(df['production_amount'], kde=True)\n",
    "# plt.title('Distribution of Crop Production')\n",
    "# plt.xlabel('Production Amount')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# correlation_matrix = df.corr()\n",
    "# plt.figure(figsize=(14, 10))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3f243",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b782aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Example:\n",
    "# df = df.dropna()  # Or use imputation methods\n",
    "\n",
    "# Handle categorical variables\n",
    "# Example:\n",
    "# df = pd.get_dummies(df, columns=['categorical_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# \n",
    "# # Choose scaler based on your data requirements\n",
    "# scaler = StandardScaler()  # or MinMaxScaler()\n",
    "# \n",
    "# # Select only numerical columns for scaling\n",
    "# numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751d820",
   "metadata": {},
   "source": [
    "## 4. Feature Selection/Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using a simple model\n",
    "# from sklearn.ensemble import RandomForestRegressor  # or RandomForestClassifier for classification tasks\n",
    "# \n",
    "# # Define features and target\n",
    "# X = df.drop('target_column', axis=1)\n",
    "# y = df['target_column']\n",
    "# \n",
    "# # Train a random forest model\n",
    "# model = RandomForestRegressor()\n",
    "# model.fit(X, y)\n",
    "# \n",
    "# # Get feature importances\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': X.columns,\n",
    "#     'Importance': model.feature_importances_\n",
    "# }).sort_values('Importance', ascending=False)\n",
    "# \n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "# plt.title('Top 15 Important Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "# from sklearn.decomposition import PCA\n",
    "# \n",
    "# # Apply PCA\n",
    "# pca = PCA(n_components=0.95)  # Keep components that explain 95% of variance\n",
    "# X_pca = pca.fit_transform(X)\n",
    "# \n",
    "# # Plot explained variance ratio\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cc960",
   "metadata": {},
   "source": [
    "## 5. Model Selection & Training\n",
    "\n",
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fe2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708922d5",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression / Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression tasks\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# \n",
    "# model1 = LinearRegression()\n",
    "# model1.fit(X_train, y_train)\n",
    "# y_pred_model1 = model1.predict(X_test)\n",
    "# \n",
    "# # Evaluate\n",
    "# mse_model1 = mean_squared_error(y_test, y_pred_model1)\n",
    "# rmse_model1 = np.sqrt(mse_model1)\n",
    "# r2_model1 = model1.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Model 1 - Linear Regression:')\n",
    "# print(f'MSE: {mse_model1:.4f}')\n",
    "# print(f'RMSE: {rmse_model1:.4f}')\n",
    "# print(f'R²: {r2_model1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f9f9a",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76352c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor  # or RandomForestClassifier\n",
    "# \n",
    "# model2 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# model2.fit(X_train, y_train)\n",
    "# y_pred_model2 = model2.predict(X_test)\n",
    "# \n",
    "# # Evaluate\n",
    "# mse_model2 = mean_squared_error(y_test, y_pred_model2)\n",
    "# rmse_model2 = np.sqrt(mse_model2)\n",
    "# r2_model2 = model2.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Model 2 - Random Forest:')\n",
    "# print(f'MSE: {mse_model2:.4f}')\n",
    "# print(f'RMSE: {rmse_model2:.4f}')\n",
    "# print(f'R²: {r2_model2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42469ecb",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor  # or GradientBoostingClassifier\n",
    "# \n",
    "# model3 = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "# model3.fit(X_train, y_train)\n",
    "# y_pred_model3 = model3.predict(X_test)\n",
    "# \n",
    "# # Evaluate\n",
    "# mse_model3 = mean_squared_error(y_test, y_pred_model3)\n",
    "# rmse_model3 = np.sqrt(mse_model3)\n",
    "# r2_model3 = model3.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Model 3 - Gradient Boosting:')\n",
    "# print(f'MSE: {mse_model3:.4f}')\n",
    "# print(f'RMSE: {rmse_model3:.4f}')\n",
    "# print(f'R²: {r2_model3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82256ad9",
   "metadata": {},
   "source": [
    "### Model 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e321ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR  # or SVC for classification\n",
    "# \n",
    "# model4 = SVR(kernel='rbf')\n",
    "# model4.fit(X_train, y_train)\n",
    "# y_pred_model4 = model4.predict(X_test)\n",
    "# \n",
    "# # Evaluate\n",
    "# mse_model4 = mean_squared_error(y_test, y_pred_model4)\n",
    "# rmse_model4 = np.sqrt(mse_model4)\n",
    "# r2_model4 = model4.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Model 4 - Support Vector Machine:')\n",
    "# print(f'MSE: {mse_model4:.4f}')\n",
    "# print(f'RMSE: {rmse_model4:.4f}')\n",
    "# print(f'R²: {r2_model4:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76984c",
   "metadata": {},
   "source": [
    "### Model 5: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647095e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# \n",
    "# # For regression\n",
    "# model5 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "# model5.fit(X_train, y_train)\n",
    "# y_pred_model5 = model5.predict(X_test)\n",
    "# \n",
    "# # Evaluate\n",
    "# mse_model5 = mean_squared_error(y_test, y_pred_model5)\n",
    "# rmse_model5 = np.sqrt(mse_model5)\n",
    "# r2_model5 = model5.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Model 5 - XGBoost:')\n",
    "# print(f'MSE: {mse_model5:.4f}')\n",
    "# print(f'RMSE: {rmse_model5:.4f}')\n",
    "# print(f'R²: {r2_model5:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2a645",
   "metadata": {},
   "source": [
    "### Compare with Auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install Auto-sklearn if not already installed\n",
    "# # !pip install auto-sklearn\n",
    "# \n",
    "# import autosklearn.regression  # or autosklearn.classification\n",
    "# import sklearn.metrics\n",
    "# \n",
    "# # Initialize auto-sklearn\n",
    "# automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "#     time_left_for_this_task=120,  # seconds\n",
    "#     per_run_time_limit=30,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# \n",
    "# # Fit auto-sklearn\n",
    "# automl.fit(X_train, y_train)\n",
    "# \n",
    "# # Evaluate\n",
    "# y_pred_auto = automl.predict(X_test)\n",
    "# mse_auto = mean_squared_error(y_test, y_pred_auto)\n",
    "# rmse_auto = np.sqrt(mse_auto)\n",
    "# r2_auto = sklearn.metrics.r2_score(y_test, y_pred_auto)\n",
    "# \n",
    "# print(f'Auto-sklearn:')\n",
    "# print(f'MSE: {mse_auto:.4f}')\n",
    "# print(f'RMSE: {rmse_auto:.4f}')\n",
    "# print(f'R²: {r2_auto:.4f}')\n",
    "# \n",
    "# # Show models found by auto-sklearn\n",
    "# print(\"Models found by auto-sklearn:\")\n",
    "# print(automl.leaderboard())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff53ce",
   "metadata": {},
   "source": [
    "## 6. Model Hyperparameter Tuning\n",
    "\n",
    "Let's tune the hyperparameters of the best-performing model from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for Random Forest hyperparameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# \n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# \n",
    "# # Create GridSearchCV object\n",
    "# grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# \n",
    "# # Fit GridSearchCV\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# \n",
    "# # Best parameters\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# \n",
    "# # Best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# \n",
    "# # Evaluate best model\n",
    "# y_pred_best = best_model.predict(X_test)\n",
    "# mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "# rmse_best = np.sqrt(mse_best)\n",
    "# r2_best = best_model.score(X_test, y_test)\n",
    "# \n",
    "# print(f'Best Tuned Model:')\n",
    "# print(f'MSE: {mse_best:.4f}')\n",
    "# print(f'RMSE: {rmse_best:.4f}')\n",
    "# print(f'R²: {r2_best:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3bd03",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d844bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison dataframe of all models\n",
    "# models_comparison = pd.DataFrame({\n",
    "#     'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'SVM', 'XGBoost', 'Auto-sklearn', 'Tuned Best Model'],\n",
    "#     'MSE': [mse_model1, mse_model2, mse_model3, mse_model4, mse_model5, mse_auto, mse_best],\n",
    "#     'RMSE': [rmse_model1, rmse_model2, rmse_model3, rmse_model4, rmse_model5, rmse_auto, rmse_best],\n",
    "#     'R²': [r2_model1, r2_model2, r2_model3, r2_model4, r2_model5, r2_auto, r2_best]\n",
    "# })\n",
    "# \n",
    "# models_comparison.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# \n",
    "# # RMSE comparison\n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.barplot(x='Model', y='RMSE', data=models_comparison)\n",
    "# plt.title('RMSE Comparison (Lower is Better)')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# \n",
    "# # R² comparison\n",
    "# plt.subplot(1, 2, 2)\n",
    "# sns.barplot(x='Model', y='R²', data=models_comparison)\n",
    "# plt.title('R² Comparison (Higher is Better)')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9de2f",
   "metadata": {},
   "source": [
    "## 8. Feature Importance and Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e01012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best performing model (assuming it's a tree-based model like Random Forest)\n",
    "# if hasattr(best_model, 'feature_importances_'):\n",
    "#     # Get feature importances\n",
    "#     feature_importances = pd.DataFrame({\n",
    "#         'Feature': X.columns,\n",
    "#         'Importance': best_model.feature_importances_\n",
    "#     }).sort_values('Importance', ascending=False)\n",
    "#     \n",
    "#     # Plot feature importances\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     sns.barplot(x='Importance', y='Feature', data=feature_importances.head(15))\n",
    "#     plt.title('Top 15 Important Features')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96df73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values for model interpretation\n",
    "# !pip install shap\n",
    "# import shap\n",
    "# \n",
    "# # Initialize SHAP explainer\n",
    "# explainer = shap.Explainer(best_model)\n",
    "# shap_values = explainer(X_test)\n",
    "# \n",
    "# # Summary plot\n",
    "# shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e38c11",
   "metadata": {},
   "source": [
    "## 9. Conclusions and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5365cf0",
   "metadata": {},
   "source": [
    "### Summary of Findings\n",
    "\n",
    "[Summarize the key findings from your analysis. Which model performed best? What features were most important? What insights were gained about the problem domain?]\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "[Discuss the practical applications of your findings. How can your model be used in the real world? What recommendations would you make based on your analysis?]\n",
    "\n",
    "### Limitations and Future Work\n",
    "\n",
    "[Discuss the limitations of your approach and potential avenues for future work. What improvements could be made? What additional data or features would be helpful?]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
